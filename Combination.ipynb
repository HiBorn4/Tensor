{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYs7BSKW5Gqk"
   },
   "source": [
    "**Loading** CMU-MOSI **dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f80j9mDfld4U",
    "outputId": "8e523faf-d059-4f83-fa41-6b70d239469b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'MultiBench'...\n",
      "remote: Enumerating objects: 6943, done.\u001b[K\n",
      "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
      "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
      "remote: Total 6943 (delta 72), reused 121 (delta 60), pack-reused 6789\u001b[K\n",
      "Receiving objects: 100% (6943/6943), 51.07 MiB | 2.93 MiB/s, done.\n",
      "Resolving deltas: 100% (4258/4258), done.\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/pliang279/MultiBench.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4h7C4XAqNTq",
    "outputId": "9fd4b50f-6592-440b-a685-94aeaada5d9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hi-born4/6th Sem/Applied Linear Algebra for Machine Learning/Tensor fusion network for multi modal sentiment analysis/MultiBench\n"
     ]
    }
   ],
   "source": [
    "# %cd MultiBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbL-Wu23sEAO",
    "outputId": "8f75f155-8677-417d-9282-fbf25095f3d7"
   },
   "outputs": [],
   "source": [
    "# !mkdir data\n",
    "# !pip install gdown && gdown https://drive.google.com/u/0/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DT1jN1eqsJio"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ye24eAGqsP3p"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dynamic module does not define module export function (PyInit__torchtext)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import the associated dataloader for affect datasets, which MOSI is a part of.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maffect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mget_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataloader\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create the training, validation, and test-set dataloaders.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m traindata, validdata, testdata \u001b[38;5;241m=\u001b[39m get_dataloader(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmosi_raw.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, robust_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, max_pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmosi\u001b[39m\u001b[38;5;124m'\u001b[39m, max_seq_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[0;32m~/6th Sem/Applied Linear Algebra for Machine Learning/Tensor fusion network for multi modal sentiment analysis/datasets/affect/get_data.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtext\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequence\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torchtext/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_torch_home\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m      8\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torchtext/_extension.py:64\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torchtext/_extension.py:61\u001b[0m, in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m _load_lib(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibtorchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n",
      "\u001b[0;31mImportError\u001b[0m: dynamic module does not define module export function (PyInit__torchtext)"
     ]
    }
   ],
   "source": [
    "# Import the associated dataloader for affect datasets, which MOSI is a part of.\n",
    "from datasets.affect.get_data import get_dataloader\n",
    "\n",
    "# Create the training, validation, and test-set dataloaders.\n",
    "traindata, validdata, testdata = get_dataloader(\n",
    "    'mosi_raw.pkl', robust_test=False, max_pad=True, data_type='mosi', max_seq_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XxYK0uvZXbvY",
    "outputId": "068e7871-0acb-4b35-d39f-9602ef4253ab"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'traindata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtraindata\u001b[49m:\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;28mprint\u001b[39m(batch)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'traindata' is not defined"
     ]
    }
   ],
   "source": [
    "for batch in traindata:\n",
    "  print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFkqO1W-hI9n"
   },
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEkie_f1cqcG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SubnetModel(nn.Module):\n",
    "    def __init__(self,input_size,num_utterances,fc1_size, fc2_size,fc3_size,dropout=0.15):\n",
    "        super(SubnetModel, self).__init__()\n",
    "\n",
    "        # self.output_range = Parameter(torch.FloatTensor([6]), requires_grad=False)\n",
    "        # self.output_shift = Parameter(torch.FloatTensor([-3]), requires_grad=False)\n",
    "        # # self.weight_decay=weight_decay\n",
    "\n",
    "        # self.norm = nn.BatchNorm1d(input_size)\n",
    "        self.drop = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Fully connected layers\n",
    "\n",
    "        #fc1 gets hidden_size dimension values as input\n",
    "        self.fc1 = nn.Linear(input_size, fc1_size)\n",
    "        self.fc2 = nn.Linear(fc1_size, fc2_size)\n",
    "        self.fc3 = nn.Linear(fc2_size, fc3_size)\n",
    "\n",
    "        # Output layer\n",
    "        # self.output_layer = nn.Linear(fc3_size, 1)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x=x.view(x.size(0),-1) # flattening the input to feed to the fully connected layer as it expects 1D input\n",
    "        # print(x.shape)\n",
    "        # normed = self.norm(x)\n",
    "        # dropped = self.drop(normed)\n",
    "\n",
    "        # x = F.normalize(x, p=2, dim=1)\n",
    "        x = torch.mean(x, dim=1)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        nan_mask = torch.isnan(x)\n",
    "        # Replace NaN values with zeros\n",
    "        x[nan_mask] = 0\n",
    "\n",
    "        # normed = self.norm(x)\n",
    "\n",
    "        fc1_out = self.relu(self.fc1(x))\n",
    "\n",
    "        fc2_out = self.relu(self.fc2(fc1_out))\n",
    "        drop=self.drop(fc2_out)\n",
    "\n",
    "        fc3_out=self.relu(self.fc3(drop))\n",
    "\n",
    "        return fc3_out\n",
    "\n",
    "        # # Output layer with Sigmoid activation\n",
    "        # output = self.sigmoid(self.output_layer(fc3_out))\n",
    "\n",
    "        # # get output between -3 and +3\n",
    "\n",
    "        # output=output*self.output_range+self.output_shift\n",
    "\n",
    "\n",
    "        # return output\n",
    "\n",
    "    # def l2_regularization_loss(self):\n",
    "    #     l2_loss = 0.0\n",
    "    #     for param in self.parameters():\n",
    "    #         l2_loss += torch.norm(param, p=2)  # L2 norm of the parameters\n",
    "    #     return self.weight_decay * l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcVZJRGndvbw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class TextModel(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_layers,fc1_size, fc2_size):\n",
    "        super(TextModel, self).__init__()\n",
    "\n",
    "        # self.output_range = Parameter(torch.FloatTensor([6]), requires_grad=False)\n",
    "        # self.output_shift = Parameter(torch.FloatTensor([-3]), requires_grad=False)\n",
    "\n",
    "        # LSTM layer (stacked LSTM)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,batch_first=True)\n",
    "\n",
    "        # Fully connected layers\n",
    "\n",
    "        #fc1 gets hidden_size dimension values as input\n",
    "        self.fc1 = nn.Linear(hidden_size, fc1_size)\n",
    "        self.fc2 = nn.Linear(fc1_size, fc2_size)\n",
    "\n",
    "        self.dropout=nn.Dropout(p=0.15)\n",
    "\n",
    "\n",
    "        # Output layer\n",
    "        # self.output_layer = nn.Linear(fc2_size, 1)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.view(-1, x.size(-1), x.size(-2))\n",
    "\n",
    "        # LSTM layer\n",
    "\n",
    "        lstm_out, (hidden_states, cell_states) = self.lstm(x)\n",
    "        # last_time_step_index = lstm_out.size(1) - 1\n",
    "\n",
    "        # # # Extract the output of the final LSTM unit\n",
    "        # final_lstm_output = lstm_out[:, last_time_step_index, :]\n",
    "\n",
    "        # print(lstm_out.shape)\n",
    "        # print(hidden_states.shape)\n",
    "        # print(type(hidden_states))\n",
    "\n",
    "        #print(hidden_states.squeeze().shape)\n",
    "\n",
    "        fc1_out = self.relu(self.fc1(hidden_states.squeeze()))\n",
    "        drop=self.dropout(fc1_out)\n",
    "\n",
    "        fc2_out = self.relu(self.fc2(drop))\n",
    "\n",
    "        return fc2_out\n",
    "\n",
    "        # # Output layer with Sigmoid activation\n",
    "        # output = self.sigmoid(self.output_layer(fc2_out))\n",
    "        # #get output between -3 and +3\n",
    "        # output=output*self.output_range+self.output_shift\n",
    "\n",
    "        # return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0LDfUqSga0P"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class TFN(nn.Module):\n",
    "    def __init__(self,audio_params,video_params,text_params,SIN_params):\n",
    "        super(TFN, self).__init__()\n",
    "\n",
    "        self.output_range = Parameter(torch.FloatTensor([6]), requires_grad=False)\n",
    "        self.output_shift = Parameter(torch.FloatTensor([-3]), requires_grad=False)\n",
    "\n",
    "        self.audio_params=audio_params\n",
    "        self.video_params=video_params\n",
    "        self.text_params=text_params\n",
    "\n",
    "        #unimodels\n",
    "        self.audio_subnet=SubnetModel(audio_params[0],audio_params[1],audio_params[2],audio_params[3],audio_params[4])\n",
    "        self.video_subnet=SubnetModel(video_params[0],video_params[1],video_params[2],video_params[3],video_params[4])\n",
    "        self.text_subnet=TextModel(text_params[0],text_params[1],text_params[2],text_params[3],text_params[4])\n",
    "\n",
    "        # Fully connected layers\n",
    "\n",
    "        #fc1 gets hidden_size dimension values as input\n",
    "        self.fc1 = nn.Linear(((audio_params[2]+1)*(video_params[2]+1)*(text_params[3]+1)), SIN_params[0])\n",
    "        self.fc2 = nn.Linear(SIN_params[0], SIN_params[1])\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(SIN_params[1], 1)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        DTYPE = torch.FloatTensor\n",
    "\n",
    "        batch_size=x[0].shape[0]\n",
    "\n",
    "        # unimodal outputs\n",
    "\n",
    "        audio_out=self.audio_subnet(x[0])\n",
    "        video_out=self.video_subnet(x[1])\n",
    "        text_out=self.text_subnet(x[2])\n",
    "\n",
    "        # adding 1 to increase the dimension value\n",
    "\n",
    "        audio_out = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), audio_out), dim=1)\n",
    "        # print(\"audio_out\")\n",
    "        # print(audio_out.shape)\n",
    "        video_out = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), video_out), dim=1)\n",
    "        # print(\"video_out\")\n",
    "        # print(video_out.shape)\n",
    "        text_out = torch.cat((Variable(torch.ones(batch_size, 1).type(DTYPE), requires_grad=False), text_out), dim=1)\n",
    "        # print(\"text_out\")\n",
    "        # print(text_out.shape)\n",
    "\n",
    "\n",
    "        # tensorfusion operation\n",
    "\n",
    "        fusion_tensor = torch.bmm(audio_out.unsqueeze(2), video_out.unsqueeze(1))\n",
    "        # print(\"fusion tensor 1\")\n",
    "        # print(fusion_tensor.shape)\n",
    "        fusion_tensor = fusion_tensor.view(-1, (self.audio_params[2] + 1) * (self.video_params[2] + 1), 1)\n",
    "        # print(\"fusion tensor 2\")\n",
    "        # print(fusion_tensor.shape)\n",
    "        fusion_tensor = torch.bmm(fusion_tensor, text_out.unsqueeze(1)).view(batch_size, -1)\n",
    "        # print(\"fusion tensor 3\")\n",
    "        # print(fusion_tensor.shape)\n",
    "\n",
    "\n",
    "        # sentiment inference network (SIN)\n",
    "\n",
    "        fc1_out = self.relu(self.fc1(fusion_tensor))\n",
    "\n",
    "        fc2_out = self.relu(self.fc2(fc1_out))\n",
    "\n",
    "        # Output layer with Sigmoid activation\n",
    "        output = self.sigmoid(self.output_layer(fc2_out))\n",
    "\n",
    "        # print(\"output\")\n",
    "        # print(\"output.shape\")\n",
    "\n",
    "        # get output between -3 and +3\n",
    "        output=output*self.output_range+self.output_shift\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vf3Zk87ghD2O"
   },
   "source": [
    "**-------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cv6JFvPMo9Sr"
   },
   "outputs": [],
   "source": [
    "audio_params=(35,50,32,32,32) # (feature_length,max_seq_len,fc1_size,fc2_size,fc3_size)\n",
    "video_params=(74,50,32,32,32) # (feature_length,max_seq_len,fc1_size,fc2_size,fc3_size)\n",
    "text_params=(300,128,1,128,128) # (feature_length,LSTM_hidden_size,num_LSTM_layers,fc1_size,fc2_size)\n",
    "\n",
    "SIN_params=(128,128)\n",
    "\n",
    "final_model=TFN(audio_params,video_params,text_params,SIN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_C-rC-Itq9G"
   },
   "outputs": [],
   "source": [
    "Loss = torch.nn.MSELoss() # mean absolute error\n",
    "optimizer = torch.optim.Adam(list(final_model.parameters())[2:],lr=0.0005,weight_decay=0.01)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6eAovmM4tcIp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PHS0TU9AtcIp",
    "outputId": "a496df33-d81d-41be-abff-d4b703391fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH :  1\n",
      "-------------Training----------------\n",
      "Epoch [1/100], Loss: 2.3177\n",
      "--------------Validation----------\n",
      "Epoch [1/100], Validation Loss: 2.6593, R2 Score: -0.0340\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  2\n",
      "-------------Training----------------\n",
      "Epoch [2/100], Loss: 2.2154\n",
      "--------------Validation----------\n",
      "Epoch [2/100], Validation Loss: 2.6288, R2 Score: -0.0189\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  3\n",
      "-------------Training----------------\n",
      "Epoch [3/100], Loss: 2.2167\n",
      "--------------Validation----------\n",
      "Epoch [3/100], Validation Loss: 2.5608, R2 Score: 0.0122\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  4\n",
      "-------------Training----------------\n",
      "Epoch [4/100], Loss: 2.1827\n",
      "--------------Validation----------\n",
      "Epoch [4/100], Validation Loss: 2.6125, R2 Score: -0.0118\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  5\n",
      "-------------Training----------------\n",
      "Epoch [5/100], Loss: 2.1128\n",
      "--------------Validation----------\n",
      "Epoch [5/100], Validation Loss: 2.6083, R2 Score: -0.0055\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  6\n",
      "-------------Training----------------\n",
      "Epoch [6/100], Loss: 2.0593\n",
      "--------------Validation----------\n",
      "Epoch [6/100], Validation Loss: 2.5199, R2 Score: 0.0300\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  7\n",
      "-------------Training----------------\n",
      "Epoch [7/100], Loss: 2.1112\n",
      "--------------Validation----------\n",
      "Epoch [7/100], Validation Loss: 2.5437, R2 Score: 0.0215\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  8\n",
      "-------------Training----------------\n",
      "Epoch [8/100], Loss: 2.0434\n",
      "--------------Validation----------\n",
      "Epoch [8/100], Validation Loss: 2.5652, R2 Score: 0.0122\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  9\n",
      "-------------Training----------------\n",
      "Epoch [9/100], Loss: 2.0242\n",
      "--------------Validation----------\n",
      "Epoch [9/100], Validation Loss: 2.5192, R2 Score: 0.0348\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  10\n",
      "-------------Training----------------\n",
      "Epoch [10/100], Loss: 2.0544\n",
      "--------------Validation----------\n",
      "Epoch [10/100], Validation Loss: 2.5101, R2 Score: 0.0334\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  11\n",
      "-------------Training----------------\n",
      "Epoch [11/100], Loss: 1.9715\n",
      "--------------Validation----------\n",
      "Epoch [11/100], Validation Loss: 2.5416, R2 Score: 0.0183\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  12\n",
      "-------------Training----------------\n",
      "Epoch [12/100], Loss: 2.0235\n",
      "--------------Validation----------\n",
      "Epoch [12/100], Validation Loss: 2.4623, R2 Score: 0.0530\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  13\n",
      "-------------Training----------------\n",
      "Epoch [13/100], Loss: 1.9348\n",
      "--------------Validation----------\n",
      "Epoch [13/100], Validation Loss: 2.5022, R2 Score: 0.0394\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  14\n",
      "-------------Training----------------\n",
      "Epoch [14/100], Loss: 1.9241\n",
      "--------------Validation----------\n",
      "Epoch [14/100], Validation Loss: 2.6354, R2 Score: -0.0221\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  15\n",
      "-------------Training----------------\n",
      "Epoch [15/100], Loss: 1.9601\n",
      "--------------Validation----------\n",
      "Epoch [15/100], Validation Loss: 2.5742, R2 Score: 0.0047\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  16\n",
      "-------------Training----------------\n",
      "Epoch [16/100], Loss: 2.0097\n",
      "--------------Validation----------\n",
      "Epoch [16/100], Validation Loss: 2.4993, R2 Score: 0.0373\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  17\n",
      "-------------Training----------------\n",
      "Epoch [17/100], Loss: 1.8704\n",
      "--------------Validation----------\n",
      "Epoch [17/100], Validation Loss: 2.5389, R2 Score: 0.0207\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  18\n",
      "-------------Training----------------\n",
      "Epoch [18/100], Loss: 1.9052\n",
      "--------------Validation----------\n",
      "Epoch [18/100], Validation Loss: 2.5436, R2 Score: 0.0158\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  19\n",
      "-------------Training----------------\n",
      "Epoch [19/100], Loss: 1.9362\n",
      "--------------Validation----------\n",
      "Epoch [19/100], Validation Loss: 2.5763, R2 Score: 0.0036\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  20\n",
      "-------------Training----------------\n",
      "Epoch [20/100], Loss: 1.8569\n",
      "--------------Validation----------\n",
      "Epoch [20/100], Validation Loss: 2.5207, R2 Score: 0.0269\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  21\n",
      "-------------Training----------------\n",
      "Epoch [21/100], Loss: 1.8269\n",
      "--------------Validation----------\n",
      "Epoch [21/100], Validation Loss: 2.5805, R2 Score: 0.0003\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  22\n",
      "-------------Training----------------\n",
      "Epoch [22/100], Loss: 1.8790\n",
      "--------------Validation----------\n",
      "Epoch [22/100], Validation Loss: 2.5622, R2 Score: 0.0073\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  23\n",
      "-------------Training----------------\n",
      "Epoch [23/100], Loss: 1.8691\n",
      "--------------Validation----------\n",
      "Epoch [23/100], Validation Loss: 2.5531, R2 Score: 0.0162\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  24\n",
      "-------------Training----------------\n",
      "Epoch [24/100], Loss: 1.8064\n",
      "--------------Validation----------\n",
      "Epoch [24/100], Validation Loss: 2.7135, R2 Score: -0.0560\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  25\n",
      "-------------Training----------------\n",
      "Epoch [25/100], Loss: 1.8266\n",
      "--------------Validation----------\n",
      "Epoch [25/100], Validation Loss: 2.6133, R2 Score: -0.0142\n",
      "\n",
      " \n",
      "\n",
      "EPOCH :  26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-dab02a12f9f5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtotal_train_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnum_sequences\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print(\"EPOCH : \",epoch+1)\n",
    "    # Training\n",
    "    total_train_loss=0.0\n",
    "    num_sequences=0\n",
    "    final_model.train()  # Set the model to training mode\n",
    "    for batch in traindata:\n",
    "        # targets=targets.unsqueeze(1).repeat(1, 50, 1)\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = final_model(batch[:-1])\n",
    "        loss = Loss(outputs, batch[-1])\n",
    "        total_train_loss+=loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        num_sequences+=1\n",
    "\n",
    "    average_train_loss = total_train_loss / num_sequences\n",
    "    print(\"-------------Training----------------\")\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {average_train_loss:.4f}')\n",
    "\n",
    "    # Validation\n",
    "    final_model.eval()  # Set the model to evaluation mode\n",
    "    total_val_loss = 0.0\n",
    "    num_sequences=0\n",
    "    val_all_predictions = []\n",
    "    val_all_targets = []\n",
    "    with torch.no_grad():\n",
    "        best_val_loss = np.inf\n",
    "        patience=3\n",
    "        current_patience = patience\n",
    "\n",
    "        for batch in validdata:\n",
    "            val_targets=batch[-1]\n",
    "            val_outputs = final_model(batch[:-1])\n",
    "            val_loss = Loss(val_outputs, val_targets)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "            # Calculate R2 score\n",
    "            val_targets_np = val_targets.cpu().numpy()\n",
    "            val_outputs_np = val_outputs.cpu().numpy()\n",
    "\n",
    "\n",
    "            val_all_predictions.extend(val_outputs_np)\n",
    "            val_all_targets.extend(val_targets_np)\n",
    "            num_sequences+=1\n",
    "\n",
    "    average_val_loss = total_val_loss / num_sequences\n",
    "    r_squared = r2_score(val_all_targets, val_all_predictions)\n",
    "\n",
    "    print(\"--------------Validation----------\")\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {average_val_loss:.4f}, R2 Score: {r_squared:.4f}')\n",
    "\n",
    "    # if average_val_loss < best_val_loss:\n",
    "    #     best_val_loss=average_val_loss\n",
    "    #     current_patience=patience\n",
    "    # else:\n",
    "    #     current_patience-=1\n",
    "    #     if current_patience==0:\n",
    "    #       print(\"Model performance degarding , Early stopping!!\")\n",
    "    #       break\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eK1pV2IPtcIp",
    "outputId": "09521b66-541f-4f83-8b05-9d1b36b8c81f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 1.4757, R-squared: -0.2117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "final_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    for batch in testdata:\n",
    "        test_targets=batch[-1]\n",
    "        test_outputs = final_model(batch[:-1])\n",
    "\n",
    "        # Convert predictions and targets to numpy arrays\n",
    "        predictions = test_outputs.numpy().flatten()\n",
    "        targets = test_targets.numpy().flatten()\n",
    "\n",
    "        all_predictions.extend(predictions)\n",
    "        all_targets.extend(targets)\n",
    "\n",
    "\n",
    "    mae = mean_absolute_error(all_targets, all_predictions)\n",
    "    r_squared = r2_score(all_targets, all_predictions)\n",
    "\n",
    "    print(f'Test MAE: {mae:.4f}, R-squared: {r_squared:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9fPZKKktgNG"
   },
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qt2MvMvXth_j"
   },
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2WUXu0OYyqJ"
   },
   "source": [
    "# Saving the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8Rlev7zY02x"
   },
   "outputs": [],
   "source": [
    "torch.save(final_model.state_dict(), '/content/drive/MyDrive/multi_model_SA/TFN_MAE-1.2386_R-0.0171.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5wYH_ThV2nt"
   },
   "source": [
    "------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
